{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Hyeuk\\Anaconda3\\envs\\py3\\lib\\site-packages\\transformers\\optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.7046003937721252\n",
      "Epoch: 0, Loss: 0.29321151971817017\n",
      "Epoch: 0, Loss: 0.308997243642807\n",
      "Epoch: 0, Loss: 0.59018474817276\n",
      "Epoch: 0, Loss: 0.38808318972587585\n",
      "Epoch: 0, Loss: 0.32617413997650146\n",
      "Epoch: 0, Loss: 0.3818863034248352\n",
      "Epoch: 0, Loss: 0.24665364623069763\n",
      "Epoch: 0, Loss: 0.19962812960147858\n",
      "Epoch: 0, Loss: 0.1469956636428833\n",
      "Epoch: 0, Loss: 0.06827922910451889\n",
      "Epoch: 0, Loss: 0.15583564341068268\n",
      "Epoch: 0, Loss: 0.35108786821365356\n",
      "Epoch: 0, Loss: 0.19213221967220306\n",
      "Epoch: 0, Loss: 0.04761192575097084\n",
      "Epoch: 0, Loss: 0.17993587255477905\n",
      "Epoch: 0, Loss: 0.02243957296013832\n",
      "Epoch: 0, Loss: 0.10852734744548798\n",
      "Epoch: 0, Loss: 0.5431343913078308\n",
      "Epoch: 0, Loss: 0.2503432035446167\n",
      "Epoch: 0, Loss: 0.07736983895301819\n",
      "Epoch: 0, Loss: 0.26740533113479614\n",
      "Epoch: 0, Loss: 0.20058687031269073\n",
      "Epoch: 1, Loss: 0.24405044317245483\n",
      "Epoch: 1, Loss: 0.009687426500022411\n",
      "Epoch: 1, Loss: 0.037213221192359924\n",
      "Epoch: 1, Loss: 0.042315252125263214\n",
      "Epoch: 1, Loss: 0.07673197984695435\n",
      "Epoch: 1, Loss: 0.10564953833818436\n",
      "Epoch: 1, Loss: 0.029512692242860794\n",
      "Epoch: 1, Loss: 0.39205288887023926\n",
      "Epoch: 1, Loss: 0.16239400207996368\n",
      "Epoch: 1, Loss: 0.07879487425088882\n",
      "Epoch: 1, Loss: 0.11492425203323364\n",
      "Epoch: 1, Loss: 0.015079600736498833\n",
      "Epoch: 1, Loss: 0.023119991645216942\n",
      "Epoch: 1, Loss: 0.06156083568930626\n",
      "Epoch: 1, Loss: 0.17636995017528534\n",
      "Epoch: 1, Loss: 0.10822853446006775\n",
      "Epoch: 1, Loss: 0.006495120469480753\n",
      "Epoch: 1, Loss: 0.008295402862131596\n",
      "Epoch: 1, Loss: 0.20731113851070404\n",
      "Epoch: 1, Loss: 0.32051268219947815\n",
      "Epoch: 1, Loss: 0.21505407989025116\n",
      "Epoch: 1, Loss: 0.013537932187318802\n",
      "Epoch: 1, Loss: 0.011229120194911957\n",
      "Epoch: 2, Loss: 0.3374391496181488\n",
      "Epoch: 2, Loss: 0.14059224724769592\n",
      "Epoch: 2, Loss: 0.00527219520881772\n",
      "Epoch: 2, Loss: 0.012957402504980564\n",
      "Epoch: 2, Loss: 0.017035188153386116\n",
      "Epoch: 2, Loss: 0.14287637174129486\n",
      "Epoch: 2, Loss: 0.018447119742631912\n",
      "Epoch: 2, Loss: 0.17883019149303436\n",
      "Epoch: 2, Loss: 0.08861086517572403\n",
      "Epoch: 2, Loss: 0.111522376537323\n",
      "Epoch: 2, Loss: 0.055746980011463165\n",
      "Epoch: 2, Loss: 0.08565415441989899\n",
      "Epoch: 2, Loss: 0.023031704127788544\n",
      "Epoch: 2, Loss: 0.051301922649145126\n",
      "Epoch: 2, Loss: 0.032411716878414154\n",
      "Epoch: 2, Loss: 0.15501199662685394\n",
      "Epoch: 2, Loss: 0.12361209094524384\n",
      "Epoch: 2, Loss: 0.019291972741484642\n",
      "Epoch: 2, Loss: 0.04003775492310524\n",
      "Epoch: 2, Loss: 0.13004906475543976\n",
      "Epoch: 2, Loss: 0.1301572471857071\n",
      "Epoch: 2, Loss: 0.09722085297107697\n",
      "Epoch: 2, Loss: 0.059808433055877686\n",
      "Training complete.\n",
      "Validation Accuracy: 0.9341\n",
      "Validation Precision: 0.9538\n",
      "Validation Recall: 0.9341\n",
      "Validation F1 Score: 0.9385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./bert-classification-tokenizer\\\\tokenizer_config.json',\n",
       " './bert-classification-tokenizer\\\\special_tokens_map.json',\n",
       " './bert-classification-tokenizer\\\\vocab.txt',\n",
       " './bert-classification-tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load the dataset\n",
    "file_path = os.getcwd()+'/preprocessing.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Encode the target variable F1\n",
    "label_encoder = LabelEncoder()\n",
    "data['F1_encoded'] = label_encoder.fit_transform(data['F1'])\n",
    "\n",
    "# Extract the features and target\n",
    "X = data['grid_path'].tolist()\n",
    "y = data['F1_encoded'].tolist()\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Custom Dataset class for our data\n",
    "class GridPathDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Create dataset\n",
    "dataset = GridPathDataset(X, y, tokenizer, MAX_LEN)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Model training setup\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "EPOCHS = 3\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "val_targets = []\n",
    "val_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch in val_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "        val_targets.extend(labels.cpu().numpy())\n",
    "        val_predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(val_targets, val_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(val_targets, val_predictions, average='weighted')\n",
    "\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "print(f'Validation Precision: {precision:.4f}')\n",
    "print(f'Validation Recall: {recall:.4f}')\n",
    "print(f'Validation F1 Score: {f1:.4f}')\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained('./bert-classification-model')\n",
    "tokenizer.save_pretrained('./bert-classification-tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Hyeuk\\Anaconda3\\envs\\py3\\lib\\site-packages\\transformers\\optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.6641759276390076\n",
      "Epoch: 0, Loss: 0.32679155468940735\n",
      "Epoch: 0, Loss: 0.3807682693004608\n",
      "Epoch: 0, Loss: 0.6214563846588135\n",
      "Epoch: 0, Loss: 0.2570272386074066\n",
      "Epoch: 0, Loss: 0.44539302587509155\n",
      "Epoch: 0, Loss: 0.424823522567749\n",
      "Epoch: 0, Loss: 0.27012312412261963\n",
      "Epoch: 0, Loss: 0.27525585889816284\n",
      "Epoch: 0, Loss: 0.392438679933548\n",
      "Epoch: 0, Loss: 0.2422669231891632\n",
      "Epoch: 0, Loss: 0.2794155180454254\n",
      "Epoch: 0, Loss: 0.16546575725078583\n",
      "Epoch: 0, Loss: 0.16743475198745728\n",
      "Epoch: 0, Loss: 0.3360508382320404\n",
      "Epoch: 0, Loss: 0.18037523329257965\n",
      "Epoch: 0, Loss: 0.36529603600502014\n",
      "Epoch: 0, Loss: 0.35613390803337097\n",
      "Epoch: 0, Loss: 0.12896502017974854\n",
      "Epoch: 0, Loss: 0.24177126586437225\n",
      "Epoch: 0, Loss: 0.15172037482261658\n",
      "Epoch: 0, Loss: 0.0960768312215805\n",
      "Epoch: 0, Loss: 0.11344822496175766\n",
      "Epoch: 1, Loss: 0.1048884391784668\n",
      "Epoch: 1, Loss: 0.1511075347661972\n",
      "Epoch: 1, Loss: 0.09514636546373367\n",
      "Epoch: 1, Loss: 0.009373068809509277\n",
      "Epoch: 1, Loss: 0.10454391688108444\n",
      "Epoch: 1, Loss: 0.14857836067676544\n",
      "Epoch: 1, Loss: 0.07483723014593124\n",
      "Epoch: 1, Loss: 0.11706440150737762\n",
      "Epoch: 1, Loss: 0.028762854635715485\n",
      "Epoch: 1, Loss: 0.19091062247753143\n",
      "Epoch: 1, Loss: 0.0716753602027893\n",
      "Epoch: 1, Loss: 0.08578458428382874\n",
      "Epoch: 1, Loss: 0.035505473613739014\n",
      "Epoch: 1, Loss: 0.0052015529945492744\n",
      "Epoch: 1, Loss: 0.02456112951040268\n",
      "Epoch: 1, Loss: 0.13043157756328583\n",
      "Epoch: 1, Loss: 0.494902640581131\n",
      "Epoch: 1, Loss: 0.0024857434909790754\n",
      "Epoch: 1, Loss: 0.03337475657463074\n",
      "Epoch: 1, Loss: 0.032491616904735565\n",
      "Epoch: 1, Loss: 0.019766589626669884\n",
      "Epoch: 1, Loss: 0.11127311736345291\n",
      "Epoch: 1, Loss: 0.38933122158050537\n",
      "Epoch: 2, Loss: 0.011640485376119614\n",
      "Epoch: 2, Loss: 0.12062922865152359\n",
      "Epoch: 2, Loss: 0.026587260887026787\n",
      "Epoch: 2, Loss: 0.044813912361860275\n",
      "Epoch: 2, Loss: 0.011903367005288601\n",
      "Epoch: 2, Loss: 0.02425749972462654\n",
      "Epoch: 2, Loss: 0.02404162287712097\n",
      "Epoch: 2, Loss: 0.16476429998874664\n",
      "Epoch: 2, Loss: 0.024806182831525803\n",
      "Epoch: 2, Loss: 0.05816405639052391\n",
      "Epoch: 2, Loss: 0.027820557355880737\n",
      "Epoch: 2, Loss: 0.1447215974330902\n",
      "Epoch: 2, Loss: 0.041961878538131714\n",
      "Epoch: 2, Loss: 0.008613422513008118\n",
      "Epoch: 2, Loss: 0.2617698311805725\n",
      "Epoch: 2, Loss: 0.03076000325381756\n",
      "Epoch: 2, Loss: 0.2826383113861084\n",
      "Epoch: 2, Loss: 0.16577905416488647\n",
      "Epoch: 2, Loss: 0.21452371776103973\n",
      "Epoch: 2, Loss: 0.0021485392935574055\n",
      "Epoch: 2, Loss: 0.014513954520225525\n",
      "Epoch: 2, Loss: 0.19830015301704407\n",
      "Epoch: 2, Loss: 0.011857027187943459\n",
      "Epoch: 3, Loss: 0.09276652336120605\n",
      "Epoch: 3, Loss: 0.10139758884906769\n",
      "Epoch: 3, Loss: 0.04073287919163704\n",
      "Epoch: 3, Loss: 0.009469009935855865\n",
      "Epoch: 3, Loss: 0.0023447233252227306\n",
      "Epoch: 3, Loss: 0.023210711777210236\n",
      "Epoch: 3, Loss: 0.1102277934551239\n",
      "Epoch: 3, Loss: 0.028550324961543083\n",
      "Epoch: 3, Loss: 0.08288955688476562\n",
      "Epoch: 3, Loss: 0.031570278108119965\n",
      "Epoch: 3, Loss: 0.006122103426605463\n",
      "Epoch: 3, Loss: 0.16535352170467377\n",
      "Epoch: 3, Loss: 0.011905464343726635\n",
      "Epoch: 3, Loss: 0.12774276733398438\n",
      "Epoch: 3, Loss: 0.062144309282302856\n",
      "Epoch: 3, Loss: 0.05315791815519333\n",
      "Epoch: 3, Loss: 0.021794762462377548\n",
      "Epoch: 3, Loss: 0.06278851628303528\n",
      "Epoch: 3, Loss: 0.0019632012117654085\n",
      "Epoch: 3, Loss: 0.06817495077848434\n",
      "Epoch: 3, Loss: 0.14606644213199615\n",
      "Epoch: 3, Loss: 0.13378547132015228\n",
      "Epoch: 3, Loss: 0.09020538628101349\n",
      "Epoch: 4, Loss: 0.07262560725212097\n",
      "Epoch: 4, Loss: 0.018894849345088005\n",
      "Epoch: 4, Loss: 0.01233894843608141\n",
      "Epoch: 4, Loss: 0.028456510975956917\n",
      "Epoch: 4, Loss: 0.11066329479217529\n",
      "Epoch: 4, Loss: 0.022052235901355743\n",
      "Epoch: 4, Loss: 0.014929856173694134\n",
      "Epoch: 4, Loss: 0.004518754314631224\n",
      "Epoch: 4, Loss: 0.12013202160596848\n",
      "Epoch: 4, Loss: 0.015625033527612686\n",
      "Epoch: 4, Loss: 0.07967685163021088\n",
      "Epoch: 4, Loss: 0.013616975396871567\n",
      "Epoch: 4, Loss: 0.12012389302253723\n",
      "Epoch: 4, Loss: 0.02999873459339142\n",
      "Epoch: 4, Loss: 0.0054381429217755795\n",
      "Epoch: 4, Loss: 0.015395659022033215\n",
      "Epoch: 4, Loss: 0.27460572123527527\n",
      "Epoch: 4, Loss: 0.005067663732916117\n",
      "Epoch: 4, Loss: 0.007456688210368156\n",
      "Epoch: 4, Loss: 0.025333872064948082\n",
      "Epoch: 4, Loss: 0.005080412141978741\n",
      "Epoch: 4, Loss: 0.002578486455604434\n",
      "Epoch: 4, Loss: 0.0287017785012722\n",
      "Training complete.\n",
      "Validation Accuracy: 0.9890\n",
      "Validation Precision: 0.9906\n",
      "Validation Recall: 0.9890\n",
      "Validation F1 Score: 0.9894\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./bert-classification-tokenizer\\\\tokenizer_config.json',\n",
       " './bert-classification-tokenizer\\\\special_tokens_map.json',\n",
       " './bert-classification-tokenizer\\\\vocab.txt',\n",
       " './bert-classification-tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "file_path = os.getcwd() + '/preprocessing.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Encode the target variable F1\n",
    "label_encoder = LabelEncoder()\n",
    "data['F1_encoded'] = label_encoder.fit_transform(data['F1'])\n",
    "\n",
    "# Extract the features and target\n",
    "X = data['grid_path'].tolist()\n",
    "y = data['F1_encoded'].tolist()\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Custom Dataset class for our data\n",
    "class GridPathDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Parameters\n",
    "MAX_LEN = 128 #86\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Create dataset\n",
    "dataset = GridPathDataset(X, y, tokenizer, MAX_LEN)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Model training setup\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "EPOCHS = 5\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "val_targets = []\n",
    "val_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "        val_targets.extend(labels.cpu().numpy())\n",
    "        val_predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(val_targets, val_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(val_targets, val_predictions, average='weighted')\n",
    "\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "print(f'Validation Precision: {precision:.4f}')\n",
    "print(f'Validation Recall: {recall:.4f}')\n",
    "print(f'Validation F1 Score: {f1:.4f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(val_targets, val_predictions)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained('./bert-classification-model')\n",
    "tokenizer.save_pretrained('./bert-classification-tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(val_targets)\n",
    "print(val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
